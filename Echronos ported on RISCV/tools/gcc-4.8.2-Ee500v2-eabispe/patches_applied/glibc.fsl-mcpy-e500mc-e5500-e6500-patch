# Problem Statement:
  Implement target specific optimized memcpy for e500mc,
  32-bit e5500/e6500, 64-bit e5500/6500

# Owned by:
  Rohit [based on 'C' implementation by Ruchika Gupta & Vakul Garg]

# Actions:
  Rev1:
  * For e500mc and e5500 [64-bit] targets, we have a separate version of memcpy
    which makes use of cache management instructions.
  
  * The cache management version of memcpy is called 'largememcpy'.

  * For application portability, we have created an memcpy alias (largememcpy)
    for all other targets that do not have specific largememcpy definition.

  Rev2:
  * Updated e6500 32-bit memcpy to use ld/std instead of lwz/stw.

diff -Naur libc-default/include/string.h libc-e500mc-e5500-e6500-memcpy/include/string.h
--- libc-default/include/string.h	2013-03-20 03:58:23.811004831 -0500
+++ libc-e500mc-e5500-e6500-memcpy/include/string.h	2013-05-27 12:29:15.420001378 -0500
@@ -67,6 +67,9 @@
     }))
 #endif
 
+#if defined (__powerpc__)
+libc_hidden_proto (largememcpy)
+#endif
 libc_hidden_proto (__mempcpy)
 libc_hidden_proto (__stpcpy)
 libc_hidden_proto (__stpncpy)
diff -Naur libc-default/string/string.h libc-e500mc-e5500-e6500-memcpy/string/string.h
--- libc-default/string/string.h	2013-03-20 03:58:22.308004822 -0500
+++ libc-e500mc-e5500-e6500-memcpy/string/string.h	2013-05-27 11:04:27.524001330 -0500
@@ -44,6 +44,11 @@
 extern void *memcpy (void *__restrict __dest,
 		     __const void *__restrict __src, size_t __n)
      __THROW __nonnull ((1, 2));
+#if defined (__powerpc__)
+extern void *largememcpy (void *__restrict __dest,
+		     __const void *__restrict __src, size_t __n)
+     __THROW __nonnull ((1, 2));
+#endif
 /* Copy N bytes of SRC to DEST, guaranteeing
    correct behavior for overlapping strings.  */
 extern void *memmove (void *__dest, __const void *__src, size_t __n)
diff -Naur libc-default/sysdeps/powerpc/memcpy.c libc-e500mc-e5500-e6500-memcpy/sysdeps/powerpc/memcpy.c
--- libc-default/sysdeps/powerpc/memcpy.c	1969-12-31 18:00:00.000000000 -0600
+++ libc-e500mc-e5500-e6500-memcpy/sysdeps/powerpc/memcpy.c	2013-05-30 06:49:42.047001445 -0500
@@ -0,0 +1,4 @@
+#include <string/memcpy.c>
+
+weak_alias (memcpy, largememcpy)
+libc_hidden_def (largememcpy)
diff -Naur libc-default/sysdeps/powerpc/powerpc32/a2/memcpy.S libc-e500mc-e5500-e6500-memcpy/sysdeps/powerpc/powerpc32/a2/memcpy.S
--- libc-default/sysdeps/powerpc/powerpc32/a2/memcpy.S	2013-03-20 03:58:23.252004831 -0500
+++ libc-e500mc-e5500-e6500-memcpy/sysdeps/powerpc/powerpc32/a2/memcpy.S	2013-05-27 05:57:17.861001390 -0500
@@ -507,3 +507,5 @@
 
 END (BP_SYM (memcpy))
 libc_hidden_builtin_def (memcpy)
+weak_alias (BP_SYM (memcpy), BP_SYM (largememcpy))
+libc_hidden_def (largememcpy)
diff -Naur libc-default/sysdeps/powerpc/powerpc32/cell/memcpy.S libc-e500mc-e5500-e6500-memcpy/sysdeps/powerpc/powerpc32/cell/memcpy.S
--- libc-default/sysdeps/powerpc/powerpc32/cell/memcpy.S	2013-03-20 03:58:23.240004831 -0500
+++ libc-e500mc-e5500-e6500-memcpy/sysdeps/powerpc/powerpc32/cell/memcpy.S	2013-05-27 05:57:24.067001375 -0500
@@ -243,3 +243,5 @@
 
 END (BP_SYM (memcpy))
 libc_hidden_builtin_def (memcpy)
+weak_alias (BP_SYM (memcpy), BP_SYM (largememcpy))
+libc_hidden_def (largememcpy)
diff -Naur libc-default/sysdeps/powerpc/powerpc32/e500mc/largememcpy.S libc-e500mc-e5500-e6500-memcpy/sysdeps/powerpc/powerpc32/e500mc/largememcpy.S
--- libc-default/sysdeps/powerpc/powerpc32/e500mc/largememcpy.S	1969-12-31 18:00:00.000000000 -0600
+++ libc-e500mc-e5500-e6500-memcpy/sysdeps/powerpc/powerpc32/e500mc/largememcpy.S	2013-05-29 08:40:01.394001385 -0500
@@ -0,0 +1,586 @@
+/* Optimized memcpy implementation for e500mc 32-bit PowerPC.
+   This version uses cache management instructions.
+
+   Copyright (C) 2003, 2006, 2011 Free Software Foundation, Inc.
+   This file is part of the GNU C Library.
+
+   The GNU C Library is free software; you can redistribute it and/or
+   modify it under the terms of the GNU Lesser General Public
+   License as published by the Free Software Foundation; either
+   version 2.1 of the License, or (at your option) any later version.
+
+   The GNU C Library is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   Lesser General Public License for more details.
+
+   You should have received a copy of the GNU Lesser General Public
+   License along with the GNU C Library; if not, write to the Free
+   Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA
+   02111-1307 USA.  */
+
+#include <sysdep.h>
+#include <bp-sym.h>
+#include <bp-asm.h>
+
+/* __ptr_t [r3] largememcpy (__ptr_t dst [r3], __ptr_t src [r4], size_t len [r5]);
+   Returns 'dst'.
+
+	 r3 = destination
+	 r4 = source
+	 r5 = byte count
+	
+	 volatile fixed point registers usable:
+	 r0, r3-r12
+
+	 volatile floating point registers usable:
+	 f0-f13
+*/	 
+
+EALIGN (BP_SYM (largememcpy), 5, 0)
+	cmplw cr0,r4,r3		/* if source==destination, return */
+	beqlr cr0
+
+	cmplwi r5,8		/* if number of bytes is less than 8 (optimal value TBD), but greater than zero. copy byte-by-byte */
+	mr r6, r3
+	blt Lcopy_bytes
+
+	neg r0,r4		/* temp = r0 */
+
+	andi. r11,r0,3		/* count = r11 [temp & 3] */
+	beq L1
+
+	lwz r12,0(r4)
+	subf r5,r11,r5		/* n = n - count */
+	add r4,r4,r11
+	stw r12,0(r6)	
+	add r6,r6,r11
+L1:
+	cmplwi 7,r5,63
+	ble 7,Lcopy_remaining
+
+	andi. r10,r0,63		/* rem = r10 */
+	beq Lsrc_aligned
+
+	subf. r10,r11,r10	/* rem = rem - count; */
+	beq 0,Lsrc_aligned
+
+	srwi r11,r10,2		/* count = rem / sizeof(unsigned long); */
+	subf r5,r10,r5		/* n = n - rem; */
+	mtctr r11
+L2:
+	lwz 0,0(r4)
+	addi r4,r4,4	
+	stw 0,0(r6)
+	addi r6,r6,4	
+	bdnz L2
+
+Lsrc_aligned:	
+	srwi. r11,r5,6		/* count = n / CACHE_LINE_SIZE; */
+	beq 0, Lcopy_remaining
+	rlwinm r5,r5,0,26,31	/* rem = n % CACHE_LINE_SIZE; */
+	rlwinm. r0,r6,0,29,31
+
+	bne 0, Lcopy_nalign
+
+	cmplwi 7,r11,256	/* while (count > (L1_CACHE_SIZE/2)/CACHE_LINE_SIZE) {  */
+	ble 7, L4
+
+	addi r7,r11,-256
+	mtctr r7
+
+#ifdef SHARED
+	mflr r0
+/* Establishes GOT addressability so we can load __cache_line_size
+   from static. This value was set from the aux vector during startup.  */
+	SETUP_GOT_ACCESS(r9,got_label_1)
+	addis r9,r9,__cache_line_size-got_label_1@ha
+	lwz r9,__cache_line_size-got_label_1@l(r9)
+	mtlr r0
+#else
+/* Load __cache_line_size from static. This value was set from the
+   aux vector during startup.  */
+	lis r9,__cache_line_size@ha
+	lwz r9,__cache_line_size@l(r9)
+#endif
+	cmplwi 5,r9,64
+	li r10,256
+	li r12,64
+	bne 5,L3_NoCache
+L3:
+	dcbt r10,r4
+	dcbzl r12,r6
+#ifndef _SOFT_FLOAT
+	lfd  0, 0(r4)
+	lfd  1, 8(r4)
+	lfd  2,16(r4)
+	lfd  3,24(r4)
+	lfd  4,32(r4)
+	lfd  5,40(r4)
+	lfd  6,48(r4)
+	lfd  7,56(r4)
+	
+	stfd 0, 0(r6)
+	stfd 1, 8(r6)
+	stfd 2,16(r6)
+	stfd 3,24(r6)
+	addi r4,r4,64
+
+	stfd 4,32(r6)
+	stfd 5,40(r6)
+	stfd 6,48(r6)
+	stfd 7,56(r6)
+#else
+	lwz r0,0(r4)
+	lwz r8,4(r4)
+	lwz r9,8(r4)
+
+	stw r0,0(r6)
+	stw r8,4(r6)
+	stw r9,8(r6)
+
+	lwz r0,12(r4)
+	lwz r8,16(r4)
+	lwz r9,20(r4)
+
+	stw r0,12(r6)
+	stw r8,16(r6)
+	stw r9,20(r6)
+
+	lwz r0,24(r4)
+	lwz r8,28(r4)
+	lwz r9,32(r4)
+
+	stw r0,24(r6)
+	stw r8,28(r6)
+	stw r9,32(r6)
+
+	lwz r0,36(r4)
+	lwz r8,40(r4)
+	lwz r9,44(r4)
+
+	stw r0,36(r6)
+	stw r8,40(r6)
+	stw r9,44(r6)
+
+	lwz r0,48(r4)
+	lwz r8,52(r4)
+	lwz r9,56(r4)
+
+	stw r0,48(r6)
+	lwz r0,60(r4)
+	addi r4,r4,64
+	stw r8,52(r6)
+	stw r9,56(r6)
+	stw r0,60(r6)
+#endif
+	dcbf 0,r6
+	addi r6,r6,64
+
+	bdnz L3
+	subf r11,r7,r11
+L4:
+	mtctr r11
+L5:
+#ifndef _SOFT_FLOAT
+	lfd 0, 0(r4)
+	lfd 1, 8(r4)
+	lfd 2,16(r4)
+	lfd 3,24(r4)
+
+	stfd 0, 0(r6)
+	stfd 1, 8(r6)
+	stfd 2,16(r6)
+	stfd 3,24(r6)
+
+	lfd 0,32(r4)
+	lfd 1,40(r4)
+	lfd 2,48(r4)
+	lfd 3,56(r4)
+	addi r4,r4,64
+
+	stfd 0,32(r6)
+	stfd 1,40(r6)
+	stfd 2,48(r6)
+	stfd 3,56(r6)
+#else
+	lwz r0,0(r4)
+	lwz r8,4(r4)
+	lwz r9,8(r4)
+
+	stw r0,0(r6)
+	stw r8,4(r6)
+	stw r9,8(r6)
+
+	lwz r0,12(r4)
+	lwz r8,16(r4)
+	lwz r9,20(r4)
+
+	stw r0,12(r6)
+	stw r8,16(r6)
+	stw r9,20(r6)
+
+	lwz r0,24(r4)
+	lwz r8,28(r4)
+	lwz r9,32(r4)
+
+	stw r0,24(r6)
+	stw r8,28(r6)
+	stw r9,32(r6)
+
+	lwz r0,36(r4)
+	lwz r8,40(r4)
+	lwz r9,44(r4)
+
+	stw r0,36(r6)
+	stw r8,40(r6)
+	stw r9,44(r6)
+
+	lwz r0,48(r4)
+	lwz r8,52(r4)
+	lwz r9,56(r4)
+
+	stw r0,48(r6)
+	lwz r0,60(r4)
+	addi r4, r4, 64
+
+	stw r8,52(r6)
+	stw r9,56(r6)
+	stw r0,60(r6)
+#endif
+	addi r6,r6,64
+	bdnz L5
+Lcopy_remaining:
+	srwi.  r11,r5,3		/* count = rem / sizeof(unsigned long); */
+	rlwinm r5,r5,0,29,31	/* n =   rem % sizeof(unsigned long); */
+	beq 0, Lcopy_bytes
+
+	mtcrf   0x01,r11
+	bf cr7*4+1,16f
+
+	lwz r0,0(r4)		/* copy 32 bytes */
+	lwz r8,4(r4)
+	lwz r9,8(r4)
+
+	stw r0,0(r6)
+	stw r8,4(r6)
+	stw r9,8(r6)
+
+	lwz r0,12(r4)
+	lwz r8,16(r4)
+	lwz r9,20(r4)
+
+	stw r0,12(r6)
+	stw r8,16(r6)
+	lwz r0,24(r4)
+	lwz r8,28(r4)
+	addi r4, r4, 32	
+
+	stw r9,20(r6)
+	stw r0,24(r6)
+	stw r8,28(r6)
+	addi r6, r6, 32
+
+16:
+	bf cr7*4+2,8f
+
+	lwz r0, 0(r4)		/* copy 16 bytes */
+	lwz r7, 4(r4)
+	lwz r8, 8(r4)
+	lwz r9,12(r4)
+	addi r4, r4, 16
+
+	stw r0, 0(r6)
+	stw r7, 4(r6)
+	stw r8, 8(r6)
+	stw r9,12(r6)
+	addi r6, r6, 16
+8:
+	bf cr7*4+3, Lcopy_bytes
+	lwz r0, 0(r4)		/* copy 8 bytes */
+	lwz r7, 4(r4)
+	addi r4, r4, 8
+
+	stw r0, 0(r6)
+	stw r7, 4(r6)
+	addi r6, r6, 8
+Lcopy_bytes:
+	cmplwi cr1,r5,4
+	cmplwi cr0,r5,1
+	bgt cr1,1f		/* nb > 4?  (5, 6, 7 bytes) */
+	ble cr0,2f		/* nb <= 1? (0, 1 bytes) */
+
+	addi r0,r5,-2		/* 2, 3, 4 bytes */
+	lhz r9,0(r4)
+	lhzx r11,r4,r0
+	sth r9,0(r6)
+	sthx r11,r6,r0
+	blr
+1:
+	addi r0,r5,-4		/* 5, 6, 7 bytes */
+	lwz r9,0(r4)
+	lwzx r11,r4,r0
+	stw r9,0(r6)
+	stwx r11,r6,r0
+	blr
+2:
+	mtocrf 0x1,r5		/* nbytes == 0 ? return */
+	bflr 31
+	lbz r0,0(r4)		/* nbytes == 1 */
+	stb r0,0(r6)
+	blr
+
+Lcopy_nalign:
+	cmplwi 7,r11,256	/*while (count > (L1_CACHE_SIZE/2)/CACHE_LINE_SIZE) { */
+	ble 7, L6
+
+	addi r7,r11,-256
+	mtctr r7
+
+#ifdef SHARED
+	mflr r0
+/* Establishes GOT addressability so we can load __cache_line_size
+   from static. This value was set from the aux vector during startup.  */
+	SETUP_GOT_ACCESS(r9,got_label_2)
+	addis r9,r9,__cache_line_size-got_label_2@ha
+	lwz r9,__cache_line_size-got_label_2@l(r9)
+	mtlr r0
+#else
+/* Load __cache_line_size from static. This value was set from the
+   aux vector during startup.  */
+	lis r9,__cache_line_size@ha
+	lwz r9,__cache_line_size@l(r9)
+#endif
+	cmplwi 5,r9,64
+	li r10,256
+	li r12,64
+	bne 5,L7_NoCache
+L7:	
+	dcbt r10,r4
+	dcbzl r12,r6
+
+	lwz r0,0(r4)		/* copy 64 bytes */
+	lwz r8,4(r4)
+	lwz r9,8(r4)
+
+	stw r0,0(r6)
+	stw r8,4(r6)
+	stw r9,8(r6)
+
+	lwz r0,12(r4)
+	lwz r8,16(r4)
+	lwz r9,20(r4)
+
+	stw r0,12(r6)
+	stw r8,16(r6)
+	stw r9,20(r6)
+
+	lwz r0,24(r4)
+	lwz r8,28(r4)
+	lwz r9,32(r4)
+
+	stw r0,24(r6)
+	stw r8,28(r6)
+	stw r9,32(r6)
+
+	lwz r0,36(r4)
+	lwz r8,40(r4)
+	lwz r9,44(r4)
+
+	stw r0,36(r6)
+	stw r8,40(r6)
+	stw r9,44(r6)
+
+	lwz r0,48(r4)
+	lwz r8,52(r4)
+	lwz r9,56(r4)
+
+	stw r0,48(r6)
+	lwz r0,60(r4)
+	addi r4,r4,64	
+
+	stw r8,52(r6)
+	stw r9,56(r6)
+	stw r0,60(r6)
+
+	dcbf 0,r6
+	addi r6,r6,64
+
+	bdnz L7
+	li r11, 256
+L6:
+	mtctr r11
+L8:
+	lwz r0,0(r4)		/* copy 64 bytes */
+	lwz r8,4(r4)
+	lwz r9,8(r4)
+
+	stw r0,0(r6)
+	stw r8,4(r6)
+	stw r9,8(r6)
+
+	lwz r0,12(r4)
+	lwz r8,16(r4)
+	lwz r9,20(r4)
+
+	stw r0,12(r6)
+	stw r8,16(r6)
+	stw r9,20(r6)
+
+	lwz r0,24(r4)
+	lwz r8,28(r4)
+	lwz r9,32(r4)
+
+	stw r0,24(r6)
+	stw r8,28(r6)
+	stw r9,32(r6)
+
+	lwz r0,36(r4)
+	lwz r8,40(r4)
+	lwz r9,44(r4)
+
+	stw r0,36(r6)
+	stw r8,40(r6)
+	stw r9,44(r6)
+
+	lwz r0,48(r4)
+	lwz r8,52(r4)
+	lwz r9,56(r4)
+
+	stw r0,48(r6)
+	lwz r0,60(r4)
+	addi r4, r4, 64	
+
+	stw r8,52(r6)
+	stw r9,56(r6)
+	stw r0,60(r6)
+	addi r6, r6, 64
+
+	bdnz L8
+
+	b Lcopy_remaining
+
+L3_NoCache:
+#ifndef _SOFT_FLOAT
+	lfd  0, 0(r4)		/* copy 64 bytes */
+	lfd  1, 8(r4)
+	lfd  2,16(r4)
+	lfd  3,24(r4)
+	lfd  4,32(r4)
+	lfd  5,40(r4)
+	lfd  6,48(r4)
+	lfd  7,56(r4)
+
+	stfd 0, 0(r6)
+	stfd 1, 8(r6)
+	stfd 2,16(r6)
+	stfd 3,24(r6)
+
+	addi r4,r4,64
+
+	stfd 4,32(r6)
+	stfd 5,40(r6)
+	stfd 6,48(r6)
+	stfd 7,56(r6)
+#else
+	lwz r0,0(r4)		/* copy 64 bytes */
+	lwz r8,4(r4)
+	lwz r9,8(r4)
+
+	stw r0,0(r6)
+	stw r8,4(r6)
+	stw r9,8(r6)
+
+	lwz r0,12(r4)
+	lwz r8,16(r4)
+	lwz r9,20(r4)
+
+	stw r0,12(r6)
+	stw r8,16(r6)
+	stw r9,20(r6)
+
+	lwz r0,24(r4)
+	lwz r8,28(r4)
+	lwz r9,32(r4)
+
+	stw r0,24(r6)
+	stw r8,28(r6)
+	stw r9,32(r6)
+
+	lwz r0,36(r4)
+	lwz r8,40(r4)
+	lwz r9,44(r4)
+
+	stw r0,36(r6)
+	stw r8,40(r6)
+	stw r9,44(r6)
+
+	lwz r0,48(r4)
+	lwz r8,52(r4)
+	lwz r9,56(r4)
+
+	stw r0,48(r6)
+	lwz r0,60(r4)
+	addi r4,r4,64
+
+	stw r8,52(r6)
+	stw r9,56(r6)
+	stw r0,60(r6)
+#endif
+	addi r6,r6,64
+	bdnz L3_NoCache
+	subf r11,r7,r11
+	b L4
+
+L7_NoCache:
+	lwz r0,0(r4)		/* copy 64 bytes */
+	lwz r8,4(r4)
+	lwz r9,8(r4)
+
+	stw r0,0(r6)
+	stw r8,4(r6)
+	stw r9,8(r6)
+
+	lwz r0,12(r4)
+	lwz r8,16(r4)
+	lwz r9,20(r4)
+
+	stw r0,12(r6)
+	stw r8,16(r6)
+	stw r9,20(r6)
+
+	lwz r0,24(r4)
+	lwz r8,28(r4)
+	lwz r9,32(r4)
+
+	stw r0,24(r6)
+	stw r8,28(r6)
+	stw r9,32(r6)
+
+	lwz r0,36(r4)
+	lwz r8,40(r4)
+	lwz r9,44(r4)
+
+	stw r0,36(r6)
+	stw r8,40(r6)
+	stw r9,44(r6)
+
+	lwz r0,48(r4)
+	lwz r8,52(r4)
+	lwz r9,56(r4)
+
+	stw r0,48(r6)
+	lwz r0,60(r4)
+	addi r4,r4,64
+
+	stw r8,52(r6)
+	stw r9,56(r6)
+	stw r0,60(r6)
+	addi r6,r6,64
+
+	bdnz L7_NoCache
+	li r11,256
+	b L6
+
+END (BP_SYM (largememcpy))
+libc_hidden_def (largememcpy)
diff -Naur libc-default/sysdeps/powerpc/powerpc32/e500mc/Makefile libc-e500mc-e5500-e6500-memcpy/sysdeps/powerpc/powerpc32/e500mc/Makefile
--- libc-default/sysdeps/powerpc/powerpc32/e500mc/Makefile	1969-12-31 18:00:00.000000000 -0600
+++ libc-e500mc-e5500-e6500-memcpy/sysdeps/powerpc/powerpc32/e500mc/Makefile	2013-05-27 06:17:04.673001376 -0500
@@ -0,0 +1,5 @@
+#Makefile fragment for PowerPC e500mc core
+
+ifeq ($(subdir),string)
+sysdep_routines += largememcpy
+endif
diff -Naur libc-default/sysdeps/powerpc/powerpc32/e500mc/memcpy.S libc-e500mc-e5500-e6500-memcpy/sysdeps/powerpc/powerpc32/e500mc/memcpy.S
--- libc-default/sysdeps/powerpc/powerpc32/e500mc/memcpy.S	1969-12-31 18:00:00.000000000 -0600
+++ libc-e500mc-e5500-e6500-memcpy/sysdeps/powerpc/powerpc32/e500mc/memcpy.S	2013-05-29 08:37:48.667001382 -0500
@@ -0,0 +1,317 @@
+/* Optimized memcpy implementation for e500mc PowerPC.
+   Copyright (C) 2003, 2006, 2011 Free Software Foundation, Inc.
+   This file is part of the GNU C Library.
+
+   The GNU C Library is free software; you can redistribute it and/or
+   modify it under the terms of the GNU Lesser General Public
+   License as published by the Free Software Foundation; either
+   version 2.1 of the License, or (at your option) any later version.
+
+   The GNU C Library is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   Lesser General Public License for more details.
+
+   You should have received a copy of the GNU Lesser General Public
+   License along with the GNU C Library; if not, write to the Free
+   Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA
+   02111-1307 USA.  */
+
+#include <sysdep.h>
+#include <bp-sym.h>
+#include <bp-asm.h>
+
+/* __ptr_t [r3] memcpy (__ptr_t dst [r3], __ptr_t src [r4], size_t len [r5]);
+   Returns 'dst'.
+
+	 r3 = destination
+	 r4 = source
+	 r5 = byte count
+	
+	 volatile fixed point registers usable:
+	 r0, r3-r12
+
+	 volatile floating point registers usable:
+	 f0-f13
+*/	 
+
+EALIGN (BP_SYM (memcpy), 5, 0)
+	cmplw cr0,r4,r3		/* if source==destination, return */
+	beqlr cr0
+
+	cmplwi r5,8		/* if number of bytes is less than 8 (optimal value TBD), but greater than zero. copy byte-by-byte */
+	mr r6, r3
+	blt Lcopy_bytes
+
+	neg r0,r4		/* temp = r0 */
+	andi. r11,r0,7		/* count = r11 [temp & 7] */
+	beq L1
+
+	lwz r0,0(r4)
+	lwz r12,4(r4)
+	subf r5,r11,r5		/* n = n - count */
+	add r4,r4,r11
+	stw r0,0(r6)	
+	stw r12,4(r6)	
+	add r6,r6,r11
+L1:
+	cmplwi 7,r5,63
+	ble 7,Lcopy_remaining
+
+	srwi r11,r5,6		/*count = n / CACHE_LINE_SIZE; */
+	rlwinm r5,r5,0,26,31	/*rem = n % CACHE_LINE_SIZE; */
+	rlwinm. r0,r6,0,29,31
+
+	mtctr r11		/* move count */
+	bne 0, Lcopy_nalign8
+L5:
+#ifndef _SOFT_FLOAT
+	lfd  0, 0(r4)
+	lfd  1, 8(r4)
+	lfd  2,16(r4)
+	lfd  3,24(r4)
+
+	stfd 0, 0(r6)
+	stfd 1, 8(r6)
+	stfd 2,16(r6)
+	stfd 3,24(r6)
+
+	lfd  0,32(r4)
+	lfd  1,40(r4)
+	lfd  2,48(r4)
+	lfd  3,56(r4)
+	addi r4,r4,64
+
+	stfd 0,32(r6)
+	stfd 1,40(r6)
+	stfd 2,48(r6)
+	stfd 3,56(r6)
+#else
+	lwz r0,0(r4)
+	lwz r8,4(r4)
+	lwz r9,8(r4)
+
+	stw r0,0(r6)
+	stw r8,4(r6)
+	stw r9,8(r6)
+
+	lwz r0,12(r4)
+	lwz r8,16(r4)
+	lwz r9,20(r4)
+
+	stw r0,12(r6)
+	stw r8,16(r6)
+	stw r9,20(r6)
+
+	lwz r0,24(r4)
+	lwz r8,28(r4)
+	lwz r9,32(r4)
+
+	stw r0,24(r6)
+	stw r8,28(r6)
+	stw r9,32(r6)
+
+	lwz r0,36(r4)
+	lwz r8,40(r4)
+	lwz r9,44(r4)
+
+	stw r0,36(r6)
+	stw r8,40(r6)
+	stw r9,44(r6)
+
+	lwz r0,48(r4)
+	lwz r8,52(r4)
+	lwz r9,56(r4)
+
+	stw r0,48(r6)
+	lwz r0,60(r4)
+	addi r4,r4,64	
+	stw r8,52(r6)
+	stw r9,56(r6)
+	stw r0,60(r6)
+#endif
+	addi r6,r6,64
+	bdnz L5
+
+Lcopy_remaining:
+	srwi.  r11,r5,3		/* count = rem / sizeof(unsigned long); */
+	rlwinm r5,r5,0,29,31	/* n =   rem % sizeof(unsigned long); */
+	beq 0, Lcopy_bytes
+
+	mtcrf   0x01,r11
+	bf cr7*4+1,16f
+
+	lwz r0, 0(r4)		/* copy 32 bytes */
+	lwz r7, 4(r4)
+	lwz r8, 8(r4)
+	lwz r9,12(r4)
+
+	stw r0, 0(r6)
+	stw r7, 4(r6)
+	stw r8, 8(r6)
+	stw r9,12(r6)
+
+	lwz r0,16(r4)
+	lwz r7,20(r4)
+	lwz r8,24(r4)
+	lwz r9,28(r4)
+	addi r4,r4,32
+
+	stw r0,16(r6)
+	stw r7,20(r6)
+	stw r8,24(r6)
+	stw r9,28(r6)
+	addi r6,r6,32
+
+16:
+	bf cr7*4+2,8f
+
+	lwz r0, 0(r4)		/* copy 16 bytes */
+	lwz r7, 4(r4)
+	lwz r8, 8(r4)
+	lwz r9,12(r4)
+	addi r4,r4,16
+
+	stw r0, 0(r6)
+	stw r7, 4(r6)
+	stw r8, 8(r6)
+	stw r9,12(r6)
+	addi r6,r6,16
+8:
+	bf cr7*4+3, Lcopy_bytes
+	lwz r0,0(r4)		/* copy 8 bytes */
+	lwz r7,4(r4)
+	addi r4,r4,8
+
+	stw r0,0(r6)
+	stw r7,4(r6)
+	addi r6,r6,8
+Lcopy_bytes:
+	cmplwi cr1,r5,4
+	cmplwi cr0,r5,1
+	bgt cr1,1f		/* nb > 4?  (5, 6, 7 bytes) */
+	ble cr0,2f		/* nb <= 1? (0, 1 bytes) */
+
+	addi r0,r5,-2		/* 2, 3, 4 bytes */
+	lhz r9,0(r4)
+	lhzx r11,r4,r0
+	sth r9,0(r6)
+	sthx r11,r6,r0
+	blr
+
+1:
+	addi r0,r5,-4		/* 5, 6, 7 bytes */
+	lwz r9,0(r4)
+	lwzx r11,r4,r0
+	stw r9,0(r6)
+	stwx r11,r6,r0
+	blr
+
+2:
+	mtocrf 0x1,r5		/* nbytes == 0 ? return */
+	bflr 31
+	lbz r0,0(r4)		/* nbytes == 1 */
+	stb r0,0(r6)
+	blr
+
+Lcopy_nalign8:
+	rlwinm. r0,r6,0,30,31
+	beq 0, Lcopy_align4
+
+Lcopy_nalign:
+	lwz r0,0(r4)		/* copy 64 bytes */
+	lwz r8,4(r4)
+	lwz r9,8(r4)
+
+	stw r0,0(r6)
+	stw r8,4(r6)
+	stw r9,8(r6)
+
+	lwz r0,12(r4)
+	lwz r8,16(r4)
+	lwz r9,20(r4)
+
+	stw r0,12(r6)
+	stw r8,16(r6)
+	stw r9,20(r6)
+
+	lwz r0,24(r4)
+	lwz r8,28(r4)
+	lwz r9,32(r4)
+
+	stw r0,24(r6)
+	stw r8,28(r6)
+	stw r9,32(r6)
+
+	lwz r0,36(r4)
+	lwz r8,40(r4)
+	lwz r9,44(r4)
+
+	stw r0,36(r6)
+	stw r8,40(r6)
+	stw r9,44(r6)
+
+	lwz r0,48(r4)
+	lwz r8,52(r4)
+	lwz r9,56(r4)
+
+	stw r0,48(r6)
+	lwz r0,60(r4)
+	addi r4,r4,64	
+
+	stw r8,52(r6)
+	stw r9,56(r6)
+	stw r0,60(r6)
+	addi r6,r6,64
+
+	bdnz Lcopy_nalign
+	b Lcopy_remaining
+
+Lcopy_align4:
+	lwz r0, 0(r4)
+	lwz r7, 4(r4)
+	lwz r8, 8(r4)
+	lwz r9,12(r4)
+
+	stw r0, 0(r6)
+	stw r7, 4(r6)
+	stw r8, 8(r6)
+	stw r9,12(r6)
+
+	lwz r0,16(r4)
+	lwz r7,20(r4)
+	lwz r8,24(r4)
+	lwz r9,28(r4)
+
+	stw r0,16(r6)
+	stw r7,20(r6)
+	stw r8,24(r6)
+	stw r9,28(r6)
+
+	lwz r0,32(r4)
+	lwz r7,36(r4)
+	lwz r8,40(r4)
+	lwz r9,44(r4)
+
+	stw r0,32(r6)
+	stw r7,36(r6)
+	stw r8,40(r6)
+	stw r9,44(r6)
+
+	lwz r0,48(r4)
+	lwz r7,52(r4)
+	lwz r8,56(r4)
+	lwz r9,60(r4)
+	addi r4,r4,64
+
+	stw r0,48(r6)
+	stw r7,52(r6)
+	stw r8,56(r6)
+	stw r9,60(r6)
+	addi r6,r6,64
+
+	bdnz Lcopy_align4
+	b Lcopy_remaining
+
+END (BP_SYM (memcpy))
+libc_hidden_builtin_def (memcpy)
diff -Naur libc-default/sysdeps/powerpc/powerpc32/e5500/memcpy.S libc-e500mc-e5500-e6500-memcpy/sysdeps/powerpc/powerpc32/e5500/memcpy.S
--- libc-default/sysdeps/powerpc/powerpc32/e5500/memcpy.S	1969-12-31 18:00:00.000000000 -0600
+++ libc-e500mc-e5500-e6500-memcpy/sysdeps/powerpc/powerpc32/e5500/memcpy.S	2013-05-29 08:41:41.508001382 -0500
@@ -0,0 +1,280 @@
+/* Optimized memcpy implementation for e5500 32-bit PowerPC.
+   Copyright (C) 2003, 2006, 2011 Free Software Foundation, Inc.
+   This file is part of the GNU C Library.
+
+   The GNU C Library is free software; you can redistribute it and/or
+   modify it under the terms of the GNU Lesser General Public
+   License as published by the Free Software Foundation; either
+   version 2.1 of the License, or (at your option) any later version.
+
+   The GNU C Library is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   Lesser General Public License for more details.
+
+   You should have received a copy of the GNU Lesser General Public
+   License along with the GNU C Library; if not, write to the Free
+   Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA
+   02111-1307 USA.  */
+
+#include <sysdep.h>
+#include <bp-sym.h>
+#include <bp-asm.h>
+
+/* __ptr_t [r3] memcpy (__ptr_t dst [r3], __ptr_t src [r4], size_t len [r5]);
+   Returns 'dst'.
+
+	 r3 = destination
+	 r4 = source
+	 r5 = byte count
+	
+	 volatile fixed point registers usable:
+	 r0, r3-r12
+
+	 volatile floating point registers usable:
+	 f0-f13
+*/	 
+
+EALIGN (BP_SYM (memcpy), 5, 0)
+	cmplw cr0,r4,r3		/* if source==destination, return */
+	beqlr cr0
+
+	cmplwi r5,8		/* if number of bytes is less than 8 (optimal value TBD), but greater than zero. copy byte-by-byte  */
+	mr r6, r3
+	blt Lcopy_bytes
+
+	neg r0,r4		/* temp = r0 */
+	andi. r11,r0,3		/* count = r11 [temp & 3] */
+	beq L1
+
+	lwz r12,0(r4)
+	subf r5,r11,r5		/* n = n - count */
+	add r4,r4,r11
+	stw r12,0(r6)	
+	add r6,r6,r11
+L1:
+	cmplwi 7,r5,63
+	ble 7,Lcopy_remaining
+
+	andi. r10,r0,15		/* rem = r10 */
+	beq Lsrc_aligned
+
+	subf. r10,r11,r10	/* rem = rem - count; */
+	beq 0,Lsrc_aligned
+
+	srwi r11,r10,2		/* count = rem / sizeof(unsigned long); */
+	subf r5,r10,r5		/* n = n - rem; */
+	mtctr r11
+L2:
+	lwz 0,0(r4)
+	addi r4,r4,4
+	stw 0,0(r6)
+	addi r6,r6,4
+	bdnz L2
+
+Lsrc_aligned:
+	srwi. r11,r5,6		/* count = n / CACHE_LINE_SIZE; */
+	beq 0, Lcopy_remaining
+	rlwinm r5,r5,0,26,31	/* rem = n % CACHE_LINE_SIZE; */
+	rlwinm. r0,r6,0,29,31
+	mtctr r11		/* move count */
+	bne 0, Lcopy_nalign
+
+L5:
+#ifndef _SOFT_FLOAT
+	lfd  0, 0(r4)		/* copy 64 bytes */
+	lfd  1, 8(r4)
+	lfd  2,16(r4)
+	lfd  3,24(r4)
+
+	stfd 0, 0(r6)
+	stfd 1, 8(r6)
+	stfd 2,16(r6)
+	stfd 3,24(r6)
+
+	lfd  0,32(r4)
+	lfd  1,40(r4)
+	lfd  2,48(r4)
+	lfd  3,56(r4)
+	addi r4,r4,64
+
+	stfd 0,32(r6)
+	stfd 1,40(r6)
+	stfd 2,48(r6)
+	stfd 3,56(r6)
+	addi r6,r6,64
+#else
+	lwz r0, 0(r4)
+	lwz r7, 4(r4)
+	lwz r8, 8(r4)
+	lwz r9,12(r4)
+
+	stw r0, 0(r6)
+	stw r7, 4(r6)
+	stw r8, 8(r6)
+	stw r9,12(r6)
+
+	lwz r0,16(r4)
+	lwz r7,20(r4)
+	lwz r8,24(r4)
+	lwz r9,28(r4)
+
+	stw r0,16(r6)
+	stw r7,20(r6)
+	stw r8,24(r6)
+	stw r9,28(r6)
+
+	lwz r0,32(r4)
+	lwz r7,36(r4)
+	lwz r8,40(r4)
+	lwz r9,44(r4)
+
+	stw r0,32(r6)
+	stw r7,36(r6)
+	stw r8,40(r6)
+	stw r9,44(r6)
+
+	lwz r0,48(r4)
+	lwz r7,52(r4)
+	lwz r8,56(r4)
+	lwz r9,60(r4)
+	addi r4,r4,64
+
+	stw r0,48(r6)
+	stw r7,52(r6)
+	stw r8,56(r6)
+	stw r9,60(r6)
+	addi r6,r6,64
+#endif
+	bdnz L5
+
+Lcopy_remaining:
+	srwi.  r11,r5,3		/* count = rem / sizeof(unsigned long); */
+	rlwinm r5,r5,0,29,31	/* n =   rem % sizeof(unsigned long); */
+	beq 0, Lcopy_bytes
+
+	mtcrf   0x01,r11
+	bf cr7*4+1,16f
+
+	lwz r0, 0(r4)		/* copy 32 bytes */
+	lwz r7, 4(r4)
+	lwz r8, 8(r4)
+	lwz r9,12(r4)
+
+	stw r0, 0(r6)
+	stw r7, 4(r6)
+	stw r8, 8(r6)
+	stw r9,12(r6)
+
+	lwz r0,16(r4)
+	lwz r7,20(r4)
+	lwz r8,24(r4)
+	lwz r9,28(r4)
+	addi r4,r4,32
+
+	stw r0,16(r6)
+	stw r7,20(r6)
+	stw r8,24(r6)
+	stw r9,28(r6)
+	addi r6,r6,32
+
+16:
+	bf cr7*4+2,8f
+
+	lwz r0, 0(r4)		/* copy 16 bytes */
+	lwz r7, 4(r4)
+	lwz r8, 8(r4)
+	lwz r9,12(r4)
+	addi r4,r4,16
+
+	stw r0, 0(r6)	
+	stw r7, 4(r6)
+	stw r8, 8(r6)
+	stw r9,12(r6)
+	addi r6,r6,16
+8:
+	bf cr7*4+3, Lcopy_bytes
+	lwz r0, 0(r4)		/* copy 8 bytes */
+	lwz r7, 4(r4)
+	addi r4,r4,8
+
+	stw r0, 0(r6)
+	stw r7, 4(r6)
+	addi r6,r6,8
+Lcopy_bytes:
+	cmplwi cr1,r5,4
+	cmplwi cr0,r5,1
+	bgt cr1,1f		/* nb > 4?  (5, 6, 7 bytes) */
+	ble cr0,2f		/* nb <= 1? (0, 1 bytes) */
+
+	addi r0,r5,-2		/* 2, 3, 4 bytes */
+	lhz r9,0(r4)
+	lhzx r11,r4,r0
+	sth r9,0(r6)
+	sthx r11,r6,r0
+	blr
+1:
+	addi r0,r5,-4		/* 5, 6, 7 bytes */
+	lwz r9,0(r4)
+	lwzx r11,r4,r0
+	stw r9,0(r6)
+	stwx r11,r6,r0
+	blr
+2:
+	mtocrf 0x1,r5		/* nbytes == 0 ? return */
+	bflr 31
+	lbz r0,0(r4)		/* nbytes == 1 */
+	stb r0,0(r6)
+	blr
+
+Lcopy_nalign:
+	lwz r0, 0(r4)		/* copy 64 bytes; unaligned data */
+	lwz r7, 4(r4)
+	lwz r8, 8(r4)
+	lwz r9,12(r4)
+
+	stw r0, 0(r6)
+	stw r7, 4(r6)
+	stw r8, 8(r6)
+	stw r9,12(r6)
+
+	lwz r0,16(r4)
+	lwz r7,20(r4)
+	lwz r8,24(r4)
+	lwz r9,28(r4)
+
+	stw r0,16(r6)
+	stw r7,20(r6)
+	stw r8,24(r6)
+	stw r9,28(r6)
+
+	lwz r0,32(r4)
+	lwz r7,36(r4)
+	lwz r8,40(r4)
+	lwz r9,44(r4)
+
+	stw r0,32(r6)
+	stw r7,36(r6)
+	stw r8,40(r6)
+	stw r9,44(r6)
+
+	lwz r0,48(r4)
+	lwz r7,52(r4)
+	lwz r8,56(r4)
+	lwz r9,60(r4)
+	addi r4,r4,64
+
+	stw r0,48(r6)
+	stw r7,52(r6)
+	stw r8,56(r6)
+	stw r9,60(r6)
+	addi r6,r6,64
+
+	bdnz Lcopy_nalign
+
+	b Lcopy_remaining
+
+END (BP_SYM (memcpy))
+weak_alias (BP_SYM (memcpy), BP_SYM (largememcpy))
+libc_hidden_builtin_def (memcpy)
+libc_hidden_def (largememcpy)
diff -Naur libc-default/sysdeps/powerpc/powerpc32/e6500/memcpy.S libc-e500mc-e5500-e6500-memcpy/sysdeps/powerpc/powerpc32/e6500/memcpy.S
--- libc-default/sysdeps/powerpc/powerpc32/e6500/memcpy.S	1969-12-31 18:00:00.000000000 -0600
+++ libc-e500mc-e5500-e6500-memcpy/sysdeps/powerpc/powerpc32/e6500/memcpy.S	2013-05-29 09:02:43.713001380 -0500
@@ -0,0 +1,242 @@
+/* Optimized memcpy implementation for e6500 32-bit PowerPC.
+   Copyright (C) 2003, 2006, 2011 Free Software Foundation, Inc.
+   This file is part of the GNU C Library.
+
+   The GNU C Library is free software; you can redistribute it and/or
+   modify it under the terms of the GNU Lesser General Public
+   License as published by the Free Software Foundation; either
+   version 2.1 of the License, or (at your option) any later version.
+
+   The GNU C Library is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   Lesser General Public License for more details.
+
+   You should have received a copy of the GNU Lesser General Public
+   License along with the GNU C Library; if not, write to the Free
+   Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA
+   02111-1307 USA.  */
+
+#include <sysdep.h>
+#include <bp-sym.h>
+#include <bp-asm.h>
+
+/* __ptr_t [r3] memcpy (__ptr_t dst [r3], __ptr_t src [r4], size_t len [r5]);
+   Returns 'dst'.
+
+	 r3 = destination
+	 r4 = source
+	 r5 = byte count
+	
+	 volatile fixed point registers usable:
+	 r0, r3-r12
+
+	 volatile floating point registers usable:
+	 f0-f13
+*/	 
+
+EALIGN (BP_SYM (memcpy), 5, 0)
+	cmplw cr0,r4,r3		/* if source==destination, return.*/
+	beqlr cr0
+
+	cmplwi r5,16		/* if number of bytes is less than 8 (optimal value TBD), but greater than zero. copy byte-by-byte */
+	mr r6, r3
+	blt Lcopy_remaining
+	
+	neg r0,r3		/* temp = r0 */
+	andi. r11,r0,15		/* count = r11 [temp & 3] */
+	beq L1
+
+	lwz r0, 0(r4)
+	lwz r7, 4(r4)
+	lwz r8, 8(r4)
+	lwz r9,12(r4)
+	subf r5,r11,r5		/* n = n - count */
+	add r4,r4,r11
+
+	stw r0, 0(r6)
+	stw r7, 4(r6)
+	stw r8, 8(r6)
+	stw r9,12(r6)
+	add r6,r6,r11
+
+L1:
+	cmplwi 7,r5,63
+	ble 7,Lcopy_remaining
+
+	srwi r11,r5,6		/* count = n / CACHE_LINE_SIZE */;
+	rlwinm r5,r5,0,26,31	/* rem = n % CACHE_LINE_SIZE; */
+	rlwinm. r0,r4,0,28,31
+	mtctr r11		/* move count */
+	li r7,16
+	li r8,32
+	li r9,48
+	bne 0, Lcopy_nalign
+
+L5:
+	lvx v14,0,r4
+	lvx v15,r7,r4
+	lvx v16,r8,r4
+	lvx v17,r9,r4
+	addi r4,r4,64
+	
+	stvx v14,0,r6
+	stvx v15,r7,r6
+	stvx v16,r8,r6
+	stvx v17,r9,r6
+	addi r6,r6,64
+	bdnz L5
+
+Lcopy_remaining:
+	srwi.  r11,r5,3		/* count = rem / sizeof(unsigned long); */
+	rlwinm r5,r5,0,29,31	/* n =   rem % sizeof(unsigned long); */
+	beq 0, Lcopy_bytes
+
+	mtcrf  0x01,r11
+	bf cr7*4+1,16f
+
+	lwz r0, 0(r4)		/* copy 32 bytes */
+	lwz r7, 4(r4)
+	lwz r8, 8(r4)
+	lwz r9,12(r4)
+
+	stw r0, 0(r6)
+	stw r7, 4(r6)
+	stw r8, 8(r6)
+	stw r9,12(r6)
+
+	lwz r0,16(r4)
+	lwz r7,20(r4)
+	lwz r8,24(r4)
+	lwz r9,28(r4)
+	addi r4,r4,32
+
+	stw r0,16(r6)
+	stw r7,20(r6)
+	stw r8,24(r6)
+	stw r9,28(r6)
+	addi r6,r6,32
+
+16:
+	bf cr7*4+2,8f
+
+	lwz r0, 0(r4)		/* copy 16 bytes */
+	lwz r7, 4(r4)
+	lwz r8, 8(r4)
+	lwz r9,12(r4)
+	addi r4,r4,16
+
+	stw r0, 0(r6)	
+	stw r7, 4(r6)
+	stw r8, 8(r6)
+	stw r9,12(r6)
+	addi r6,r6,16
+8:
+	bf cr7*4+3, Lcopy_bytes
+	lwz r0, 0(r4)		/* copy 8 bytes */
+	lwz r7, 4(r4)
+	addi r4,r4,8
+	
+	stw r0, 0(r6)
+	stw r7, 4(r6)
+	addi r6,r6,8
+
+Lcopy_bytes:
+	cmplwi cr1,r5,4
+	cmplwi cr0,r5,1
+	bgt cr1,1f		/* nb > 4?  (5, 6, 7 bytes) */
+	ble cr0,2f		/* nb <= 1? (0, 1 bytes) */
+
+	addi r0,r5,-2		/* 2, 3, 4 bytes */
+	lhz r9,0(r4)
+	lhzx r11,r4,r0
+	sth r9,0(r6)
+	sthx r11,r6,r0
+	blr
+
+1:
+	addi r0,r5,-4		/* 5, 6, 7 bytes */
+	lwz r9,0(r4)
+	lwzx r11,r4,r0
+	stw r9,0(r6)
+	stwx r11,r6,r0
+	blr
+
+2:
+	mtocrf 0x1,r5		/* nbytes == 0 ? return */
+	bflr 31
+	lbz r0,0(r4)		/* nbytes == 1 */
+	stb r0,0(r6)
+	blr
+
+Lcopy_nalign:
+#ifndef _SOFT_FLOAT
+	rlwinm. r0,r4,0,29,31
+	beq 0, Lcopy_nalign_ldst
+#endif
+
+Lcopy_nalign_altivec:
+	lvx v0,0,r4 		/* load MSQ */
+	lvsl v18,0,r4 		/* set permute control vector */
+	lvx v19,r7,r4 		/* load LSQ */
+	vperm v14,v0,v19,v18 	/* align the data */
+	
+	lvx v0,r7,r4 		/* load MSQ */
+	lvsl v18,r7,r4 		/* set permute control vector */
+	lvx v19,r8,r4 		/* load LSQ */
+	vperm v15,v0,v19,v18 	/* align the data */
+
+	lvx v0,r8,r4 		/* load MSQ */
+	lvsl v18,r8,r4 		/* set permute control vector */
+	lvx v19,r9,r4 		/* load LSQ */
+	vperm v16,v0,v19,v18 	/* align the data */
+
+	lvx v0,r9,r4 		/* load MSQ */
+	lvsl v18,r9,r4 		/* set permute control vector */
+	addi r4,r4,64
+	lvx v19,0,r4 		/* load LSQ */
+	vperm v17,v0,v19,v18 	/* align the data */
+
+	stvx v14,0,r6
+	stvx v15,r7,r6
+	stvx v16,r8,r6
+	stvx v17,r9,r6
+	addi r6,r6,64
+
+	bdnz Lcopy_nalign_altivec
+
+	b Lcopy_remaining
+
+#ifndef _SOFT_FLOAT
+Lcopy_nalign_ldst:
+	lfd  0, 0(r4)		/* copy 64 bytes */
+	lfd  1, 8(r4)
+	lfd  2,16(r4)
+	lfd  3,24(r4)
+	
+	stfd 0, 0(r6)
+	stfd 1, 8(r6)
+	stfd 2,16(r6)
+	stfd 3,24(r6)
+	
+	lfd  0,32(r4)
+	lfd  1,40(r4)
+	lfd  2,48(r4)
+	lfd  3,56(r4)
+	addi r4,r4,64
+
+	stfd 0,32(r6)
+	stfd 1,40(r6)
+	stfd 2,48(r6)
+	stfd 3,56(r6)
+	addi r6,r6,64
+
+	bdnz Lcopy_nalign_ldst
+
+	b Lcopy_remaining
+#endif
+
+END (BP_SYM (memcpy))
+weak_alias (BP_SYM (memcpy), BP_SYM (largememcpy))
+libc_hidden_builtin_def (memcpy)
+libc_hidden_def (largememcpy)
diff -Naur libc-default/sysdeps/powerpc/powerpc32/power4/memcpy.S libc-e500mc-e5500-e6500-memcpy/sysdeps/powerpc/powerpc32/power4/memcpy.S
--- libc-default/sysdeps/powerpc/powerpc32/power4/memcpy.S	2013-03-20 03:58:23.240004831 -0500
+++ libc-e500mc-e5500-e6500-memcpy/sysdeps/powerpc/powerpc32/power4/memcpy.S	2013-05-27 06:01:23.596001376 -0500
@@ -424,3 +424,5 @@
 END (BP_SYM (memcpy))
 
 libc_hidden_builtin_def (memcpy)
+weak_alias (BP_SYM (memcpy), BP_SYM (largememcpy))
+libc_hidden_def (largememcpy)
diff -Naur libc-default/sysdeps/powerpc/powerpc32/power6/memcpy.S libc-e500mc-e5500-e6500-memcpy/sysdeps/powerpc/powerpc32/power6/memcpy.S
--- libc-default/sysdeps/powerpc/powerpc32/power6/memcpy.S	2013-03-20 03:58:23.254004831 -0500
+++ libc-e500mc-e5500-e6500-memcpy/sysdeps/powerpc/powerpc32/power6/memcpy.S	2013-05-27 06:01:57.127001378 -0500
@@ -841,3 +841,5 @@
 END (BP_SYM (memcpy))
 
 libc_hidden_builtin_def (memcpy)
+weak_alias (BP_SYM (memcpy), BP_SYM (largememcpy))
+libc_hidden_def (largememcpy)
diff -Naur libc-default/sysdeps/powerpc/powerpc32/power7/memcpy.S libc-e500mc-e5500-e6500-memcpy/sysdeps/powerpc/powerpc32/power7/memcpy.S
--- libc-default/sysdeps/powerpc/powerpc32/power7/memcpy.S	2013-03-20 03:58:23.244004831 -0500
+++ libc-e500mc-e5500-e6500-memcpy/sysdeps/powerpc/powerpc32/power7/memcpy.S	2013-05-27 06:02:21.171001378 -0500
@@ -525,3 +525,5 @@
 
 END (BP_SYM (memcpy))
 libc_hidden_builtin_def (memcpy)
+weak_alias (BP_SYM (memcpy), BP_SYM (largememcpy))
+libc_hidden_def (largememcpy)
diff -Naur libc-default/sysdeps/powerpc/powerpc64/a2/memcpy.S libc-e500mc-e5500-e6500-memcpy/sysdeps/powerpc/powerpc64/a2/memcpy.S
--- libc-default/sysdeps/powerpc/powerpc64/a2/memcpy.S	2013-03-20 03:58:23.231004831 -0500
+++ libc-e500mc-e5500-e6500-memcpy/sysdeps/powerpc/powerpc64/a2/memcpy.S	2013-05-27 06:02:55.804001377 -0500
@@ -499,3 +499,5 @@
 
 END_GEN_TB (BP_SYM (memcpy),TB_TOCLESS)
 libc_hidden_builtin_def (memcpy)
+weak_alias (BP_SYM (memcpy), BP_SYM (largememcpy))
+libc_hidden_def (largememcpy)
diff -Naur libc-default/sysdeps/powerpc/powerpc64/cell/memcpy.S libc-e500mc-e5500-e6500-memcpy/sysdeps/powerpc/powerpc64/cell/memcpy.S
--- libc-default/sysdeps/powerpc/powerpc64/cell/memcpy.S	2013-03-20 03:58:23.219004831 -0500
+++ libc-e500mc-e5500-e6500-memcpy/sysdeps/powerpc/powerpc64/cell/memcpy.S	2013-05-27 06:03:12.042001377 -0500
@@ -243,3 +243,5 @@
 
 END_GEN_TB (BP_SYM (memcpy),TB_TOCLESS)
 libc_hidden_builtin_def (memcpy)
+weak_alias (BP_SYM (memcpy), BP_SYM (largememcpy))
+libc_hidden_def (largememcpy)
diff -Naur libc-default/sysdeps/powerpc/powerpc64/e5500/largememcpy.S libc-e500mc-e5500-e6500-memcpy/sysdeps/powerpc/powerpc64/e5500/largememcpy.S
--- libc-default/sysdeps/powerpc/powerpc64/e5500/largememcpy.S	1969-12-31 18:00:00.000000000 -0600
+++ libc-e500mc-e5500-e6500-memcpy/sysdeps/powerpc/powerpc64/e5500/largememcpy.S	2013-05-29 08:43:16.210001383 -0500
@@ -0,0 +1,230 @@
+/* Optimized memcpy implementation for e5500 64-bit PowerPC64.
+   Copyright (C) 2003, 2006, 2011 Free Software Foundation, Inc.
+   This file is part of the GNU C Library.
+
+   The GNU C Library is free software; you can redistribute it and/or
+   modify it under the terms of the GNU Lesser General Public
+   License as published by the Free Software Foundation; either
+   version 2.1 of the License, or (at your option) any later version.
+
+   The GNU C Library is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   Lesser General Public License for more details.
+
+   You should have received a copy of the GNU Lesser General Public
+   License along with the GNU C Library; if not, write to the Free
+   Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA
+   02111-1307 USA.  */
+
+#include <sysdep.h>
+#include <bp-sym.h>
+#include <bp-asm.h>
+
+/* __ptr_t [r3] memcpy (__ptr_t dst [r3], __ptr_t src [r4], size_t len [r5]);
+   Returns 'dst'.
+
+	 r3 = destination
+	 r4 = source
+	 r5 = byte count
+	
+	 volatile fixed point registers usable:
+	 r0, r3-r12
+
+	 volatile floating point registers usable:
+	 f0-f13
+*/	 
+	.section        ".toc","aw"
+.LC0:
+	.tc __cache_line_size[TC],__cache_line_size
+	.section        ".text"
+	.align 2
+
+EALIGN (BP_SYM (largememcpy), 5, 0)
+	cmpld cr0,r4,r3			/* if source==destination, return */
+	beqlr cr0
+
+	cmpldi r5,8			/* if number of bytes is less than 8 (optimal value TBD), but greater than zero. copy byte-by-byte */
+	mr r6, r3
+	blt Lcopy_bytes
+
+	neg r0,r4			/* temp = r0 */
+	andi. r11,r0,7			/* count = r11 [temp & 7] */
+	beq L1
+
+	ld r12,0(r4)
+	subf r5,r11,r5			/* n = n - count */
+	add r4,r4,r11
+	std r12,0(r6)
+	add r6,r6,r11
+
+L1:
+	cmpldi 7,r5,63
+	ble 7,Lcopy_remaining
+
+	srwi r11,r5,6			/* count = n / CACHE_LINE_SIZE; */
+	rlwinm. r5,r5,0,26,31		/* rem = n % CACHE_LINE_SIZE; */
+
+	cmpldi 7,r11,256		/* while (count > (L1_CACHE_SIZE/2)/CACHE_LINE_SIZE) { */
+	ble 7, L4
+
+	rlwinm. r0,r6,0,28,31
+	cmpldi r0, 8
+
+	addi r7,r11,-256
+	mtctr r7
+
+	ble L3_nalign
+
+	ld  r9,.LC0@toc(r2)		/* get cache line size */
+	lwz r9,0(r9)
+	cmpldi 5,r9,64
+	li r10,256
+	li r12,64
+	bne 5,L3_nalign
+L3:
+	dcbt r10,r4
+	dcbzl r12,r6
+
+	ld  r0, 0(r4)			/* 64-byte copy */
+	ld  r7, 8(r4)
+	ld  r8,16(r4)
+	ld  r9,24(r4)
+
+	std r0, 0(r6)
+	std r7, 8(r6)
+	std r8,16(r6)
+	std r9,24(r6)
+
+	ld  r0,32(r4)
+	ld  r7,40(r4)
+	ld  r8,48(r4)
+	ld  r9,56(r4)
+	addi r4,r4,64
+
+	std r0,32(r6)
+	std r7,40(r6)
+	std r8,48(r6)
+	std r9,56(r6)
+
+	dcbf 0,r6
+	addi r6,r6,64
+
+	bdnz L3
+L6:	li r11, 256
+L4:	mtctr r11			/* move count */
+L5:
+	ld  r0, 0(r4)
+	ld  r7, 8(r4)
+	ld  r8,16(r4)
+	ld  r9,24(r4)
+
+	std r0, 0(r6)
+	std r7, 8(r6)
+	std r8,16(r6)
+	std r9,24(r6)
+
+	ld  r0,32(r4)
+	ld  r7,40(r4)
+	ld  r8,48(r4)
+	ld  r9,56(r4)
+
+	addi r4,r4,64
+
+	std r0,32(r6)
+	std r7,40(r6)
+	std r8,48(r6)
+	std r9,56(r6)
+
+	addi r6,r6,64
+	bdnz L5
+
+Lcopy_remaining:
+	srwi.  r11,r5,3			/* count = rem / sizeof(unsigned long); */
+	rlwinm r5,r5,0,29,31		/* n =   rem % sizeof(unsigned long); */
+	beq 0, Lcopy_bytes
+
+	mtcrf 0x01,r11
+	bf cr7*4+1,16f
+	ld  r0, 0(r4)			/* copy 32 byte */
+	ld  r7, 8(r4)
+	ld  r8,16(r4)
+	ld  r9,24(r4)
+	addi r4, r4, 32
+	std r0,0(r6)
+	std r7,8(r6)
+	std r8,16(r6)
+	std r9,24(r6)
+	addi r6, r6, 32
+
+16:
+	bf cr7*4+2,8f 			/* copy 16 byte */
+	ld  r7,0(r4)
+	ld  r8,8(r4)
+	addi r4, r4, 16
+	std r7,0(r6)
+	std r8,8(r6)
+	addi r6, r6, 16
+8:
+	bf cr7*4+3, Lcopy_bytes 	/* copy 8 bytes */
+	ld  r7,0(r4)
+	addi r4,r4,8
+	std r7,0(r6)
+	addi r6,r6,8
+
+Lcopy_bytes:
+	cmpldi cr1,r5,4
+	cmpldi cr0,r5,1
+	bgt cr1,1f			/* nb > 4?  (5, 6, 7 bytes) */
+	ble cr0,2f			/* nb <= 1? (0, 1 bytes) */
+
+	addi r0,r5,-2			/* 2, 3, 4 bytes */
+	lhz r9,0(r4)
+	lhzx r11,r4,r0
+	sth r9,0(r6)
+	sthx r11,r6,r0
+	blr
+1:
+	addi r0,r5,-4			/* 5, 6, 7 bytes */
+	lwz r9,0(r4)
+	lwzx r11,r4,r0
+	stw r9,0(r6)
+	stwx r11,r6,r0
+	blr
+2:
+	mtocrf 0x1,r5			/* nbytes == 0 ? return */
+	bflr 31
+	lbz r0,0(r4)			/* nbytes == 1 */
+	stb r0,0(r6)
+	blr
+
+L3_nalign:
+	ld  r0, 0(r4)
+	ld  r7, 8(r4)
+	ld  r8,16(r4)
+	ld  r9,24(r4)
+
+	std r0, 0(r6)
+	std r7, 8(r6)
+	std r8,16(r6)
+	std r9,24(r6)
+
+	ld  r0,32(r4)
+	ld  r7,40(r4)
+	ld  r8,48(r4)
+	ld  r9,56(r4)
+
+	addi r4,r4,64
+
+	std r0,32(r6)
+	std r7,40(r6)
+	std r8,48(r6)
+	std r9,56(r6)
+
+	addi r6,r6,64
+
+	bdnz L3_nalign
+	b L6
+
+END_GEN_TB (BP_SYM (largememcpy),TB_TOCLESS)
+libc_hidden_def (largememcpy)
diff -Naur libc-default/sysdeps/powerpc/powerpc64/e5500/Makefile libc-e500mc-e5500-e6500-memcpy/sysdeps/powerpc/powerpc64/e5500/Makefile
--- libc-default/sysdeps/powerpc/powerpc64/e5500/Makefile	1969-12-31 18:00:00.000000000 -0600
+++ libc-e500mc-e5500-e6500-memcpy/sysdeps/powerpc/powerpc64/e5500/Makefile	2013-05-27 06:17:40.634001372 -0500
@@ -0,0 +1,5 @@
+#Makefile fragment for PowerPC e5500 64-bit core
+
+ifeq ($(subdir),string)
+sysdep_routines += largememcpy
+endif
diff -Naur libc-default/sysdeps/powerpc/powerpc64/e5500/memcpy.S libc-e500mc-e5500-e6500-memcpy/sysdeps/powerpc/powerpc64/e5500/memcpy.S
--- libc-default/sysdeps/powerpc/powerpc64/e5500/memcpy.S	1969-12-31 18:00:00.000000000 -0600
+++ libc-e500mc-e5500-e6500-memcpy/sysdeps/powerpc/powerpc64/e5500/memcpy.S	2013-05-29 08:42:26.852001380 -0500
@@ -0,0 +1,147 @@
+/* Optimized memcpy implementation for e5500 64-bit PowerPC.
+   Copyright (C) 2003, 2006, 2011 Free Software Foundation, Inc.
+   This file is part of the GNU C Library.
+
+   The GNU C Library is free software; you can redistribute it and/or
+   modify it under the terms of the GNU Lesser General Public
+   License as published by the Free Software Foundation; either
+   version 2.1 of the License, or (at your option) any later version.
+
+   The GNU C Library is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   Lesser General Public License for more details.
+
+   You should have received a copy of the GNU Lesser General Public
+   License along with the GNU C Library; if not, write to the Free
+   Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA
+   02111-1307 USA.  */
+
+#include <sysdep.h>
+#include <bp-sym.h>
+#include <bp-asm.h>
+
+/* __ptr_t [r3] memcpy (__ptr_t dst [r3], __ptr_t src [r4], size_t len [r5]);
+   Returns 'dst'.
+
+	 r3 = destination
+	 r4 = source
+	 r5 = byte count
+	
+	 volatile fixed point registers usable:
+	 r0, r3-r12
+
+	 volatile floating point registers usable:
+	 f0-f13
+*/
+
+EALIGN (BP_SYM (memcpy), 5, 0)
+	cmpld cr0,r4,r3		/* if source==destination, return */
+	beqlr cr0
+
+	cmpldi r5,8		/* if number of bytes is less than 8 but greater than zero, copy byte-by-byte */
+	mr r6, r3
+	blt Lcopy_bytes
+
+	neg r0,r4		/* temp = r0 */
+	andi. r11,r0,7		/* count = r11 [temp & 7] */
+	beq L1
+
+	ld r12,0(r4)
+	subf r5,r11,r5		/* n = n - count */
+	add r4,r4,r11
+	std r12,0(r6)	
+	add r6,r6,r11
+
+L1:
+	cmpldi 7,r5,63
+	ble 7,Lcopy_remaining
+	srwi r11,r5,6		/* count = n / CACHE_LINE_SIZE; */
+	rlwinm. r5,r5,0,26,31	/* rem = n % CACHE_LINE_SIZE; */
+	mtctr r11		/* move count */
+L5:
+	ld  r0, 0(r4)		/* 64-byte copy */
+	ld  r7, 8(r4)
+	ld  r8,16(r4)
+	ld  r9,24(r4)
+
+	std r0, 0(r6)
+	std r7, 8(r6)
+	std r8,16(r6)
+	std r9,24(r6)
+
+	ld  r0,32(r4)
+	ld  r7,40(r4)
+	ld  r8,48(r4)
+	ld  r9,56(r4)
+	addi r4,r4,64
+
+	std r0,32(r6)
+	std r7,40(r6)
+	std r8,48(r6)
+	std r9,56(r6)
+	addi r6,r6,64
+
+	bdnz L5
+
+Lcopy_remaining:
+	srwi.  r11,r5,3		/* count = rem / sizeof(unsigned long); */
+	rlwinm r5,r5,0,29,31	/* n =   rem % sizeof(unsigned long); */
+	beq 0, Lcopy_bytes
+
+	mtcrf   0x01,r11
+	bf cr7*4+1,16f
+	ld  r0, 0(r4)		/* copy 32 bytes */
+	ld  r7, 8(r4)
+	ld  r8,16(r4)
+	ld  r9,24(r4)
+	addi r4,r4,32
+
+	std r0,0(r6)
+	std r7,8(r6)
+	std r8,16(r6)
+	std r9,24(r6)
+	addi r6,r6,32
+16:
+	bf cr7*4+2,8f
+	ld  r7,0(r4)		/* copy 16 bytes */
+	ld  r8,8(r4)
+	addi r4,r4,16
+	std r7,0(r6)
+	std r8,8(r6)
+	addi r6,r6,16
+8:
+	bf cr7*4+3, Lcopy_bytes
+	ld  r7,0(r4)		/* copy 8 bytes */
+	addi r4,r4,8
+	std r7,0(r6)
+	addi r6,r6,8
+
+Lcopy_bytes:
+	cmpldi cr1,r5,4
+	cmpldi cr0,r5,1
+	bgt cr1,1f		/* nb > 4?  (5, 6, 7 bytes) */
+	ble cr0,2f		/* nb <= 1? (0, 1 bytes) */
+
+	addi r0,r5,-2		/* 2, 3, 4 bytes */
+	lhz r9,0(r4)
+	lhzx r11,r4,r0
+	sth r9,0(r6)
+	sthx r11,r6,r0
+	blr
+1:
+	addi r0,r5,-4		/* 5, 6, 7 bytes */
+	lwz r9,0(r4)
+	lwzx r11,r4,r0
+	stw r9,0(r6)
+	stwx r11,r6,r0
+	blr
+2:
+	mtocrf 0x1,r5		/* nbytes == 0 ? return */
+	bflr 31
+	lbz r0,0(r4)		/* nbytes == 1 */
+	stb r0,0(r6)
+	blr
+
+END_GEN_TB (BP_SYM (memcpy), TB_TOCLESS)
+libc_hidden_builtin_def (memcpy)
diff -Naur libc-default/sysdeps/powerpc/powerpc64/e6500/memcpy.S libc-e500mc-e5500-e6500-memcpy/sysdeps/powerpc/powerpc64/e6500/memcpy.S
--- libc-default/sysdeps/powerpc/powerpc64/e6500/memcpy.S	1969-12-31 18:00:00.000000000 -0600
+++ libc-e500mc-e5500-e6500-memcpy/sysdeps/powerpc/powerpc64/e6500/memcpy.S	2013-05-29 09:02:25.940001380 -0500
@@ -0,0 +1,208 @@
+/* Optimized memcpy implementation for e6500 64-bit PowerPC.
+   Copyright (C) 2003, 2006, 2011 Free Software Foundation, Inc.
+   This file is part of the GNU C Library.
+
+   The GNU C Library is free software; you can redistribute it and/or
+   modify it under the terms of the GNU Lesser General Public
+   License as published by the Free Software Foundation; either
+   version 2.1 of the License, or (at your option) any later version.
+
+   The GNU C Library is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   Lesser General Public License for more details.
+
+   You should have received a copy of the GNU Lesser General Public
+   License along with the GNU C Library; if not, write to the Free
+   Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA
+   02111-1307 USA.  */
+
+#include <sysdep.h>
+#include <bp-sym.h>
+#include <bp-asm.h>
+
+/* __ptr_t [r3] memcpy (__ptr_t dst [r3], __ptr_t src [r4], size_t len [r5]);
+   Returns 'dst'.
+
+	 r3 = destination
+	 r4 = source
+	 r5 = byte count
+	
+	 volatile fixed point registers usable:
+	 r0, r3-r12
+
+	 volatile floating point registers usable:
+	 f0-f13
+*/
+
+EALIGN (BP_SYM (memcpy), 5, 0)
+	cmpld cr0,r4,r3		/* if source==destination, return */
+	beqlr cr0
+
+	cmpldi r5,16		/* if number of bytes is less than 8 but greater than zero, copy byte-by-byte */
+	mr r6, r3
+	ble Lcopy_remaining
+
+	neg r0,r3		/* temp = r0 */
+	andi. r11,r0,15		/* count = r11 [temp & 15] */
+	beq L1
+
+	ld r12,0(r4)
+	ld r0,8(r4)
+	subf r5,r11,r5		/* n = n - count */
+	add r4,r4,r11
+	std r12,0(r6)
+	std r0,8(r6)
+	add r6,r6,r11
+
+L1:
+	cmpldi 7,r5,63
+	ble 7,Lcopy_remaining
+	srwi r11,r5,6		/* count = n / CACHE_LINE_SIZE; */
+	rlwinm r5,r5,0,26,31	/* rem = n % CACHE_LINE_SIZE; */
+	rlwinm. r0,r4,0,28,31
+	mtctr r11		/* move count */
+	li r7,16
+	li r8,32
+	li r9,48
+	bne 0, Lcopy_nalign
+
+L5:
+	lvx v14,0,r4
+	lvx v15,r7,r4
+	lvx v16,r8,r4
+	lvx v17,r9,r4
+	addi r4,r4,64
+
+	stvx v14,0,r6
+	stvx v15,r7,r6
+	stvx v16,r8,r6
+	stvx v17,r9,r6
+	addi r6,r6,64
+
+	bdnz L5
+
+Lcopy_remaining:
+	srwi.  r11,r5,3		/* count = rem / sizeof(unsigned long); */
+	rlwinm r5,r5,0,29,31	/* n =   rem % sizeof(unsigned long); */
+	beq 0, Lcopy_bytes
+
+	mtcrf   0x01,r11
+	bf cr7*4+1,16f
+	ld  r0, 0(r4)		/* copy 32 bytes */
+	ld  r7, 8(r4)
+	ld  r8,16(r4)
+	ld  r9,24(r4)
+	addi r4,r4,32
+
+	std r0,0(r6)
+	std r7,8(r6)
+	std r8,16(r6)
+	std r9,24(r6)
+	addi r6,r6,32
+16:
+	bf cr7*4+2,8f
+	ld  r7,0(r4)		/* copy 16 bytes */
+	ld  r8,8(r4)
+	addi r4,r4,16
+	std r7,0(r6)
+	std r8,8(r6)
+	addi r6,r6,16
+8:
+	bf cr7*4+3, Lcopy_bytes
+	ld  r7,0(r4)		/* copy 8 bytes */
+	addi r4,r4,8
+	std r7,0(r6)
+	addi r6,r6,8
+
+Lcopy_bytes:
+	cmpldi cr1,r5,4
+	cmpldi cr0,r5,1
+	bgt cr1,1f		/* nb > 4?  (5, 6, 7 bytes) */
+	ble cr0,2f		/* nb <= 1? (0, 1 bytes) */
+
+	addi r0,r5,-2		/* 2, 3, 4 bytes */
+	lhz r9,0(r4)
+	lhzx r11,r4,r0
+	sth r9,0(r6)
+	sthx r11,r6,r0
+	blr
+1:
+	addi r0,r5,-4		/* 5, 6, 7 bytes */
+	lwz r9,0(r4)
+	lwzx r11,r4,r0
+	stw r9,0(r6)
+	stwx r11,r6,r0
+	blr
+2:
+	mtocrf 0x1,r5		/* nbytes == 0 ? return */
+	bflr 31
+	lbz r0,0(r4)		/* nbytes == 1 */
+	stb r0,0(r6)
+	blr	
+
+Lcopy_nalign:
+	rlwinm. r0,r4,0,29,31
+	beq 0, Lcopy_nalign_ldst
+
+Lcopy_nalign_altivec:	
+        lvx v0,0,r4             /* load MSQ */
+        lvsl v18,0,r4           /* set permute control vector */
+        lvx v19,r7,r4           /* load LSQ */
+        vperm v14,v0,v19,v18    /* align the data */
+
+        lvx v0,r7,r4            /* load MSQ */
+        lvsl v18,r7,r4          /* set permute control vector */
+        lvx v19,r8,r4           /* load LSQ */
+        vperm v15,v0,v19,v18    /* align the data */
+
+        lvx v0,r8,r4            /* load MSQ */
+        lvsl v18,r8,r4          /* set permute control vector */
+        lvx v19,r9,r4           /* load LSQ */
+        vperm v16,v0,v19,v18    /* align the data */
+
+        lvx v0,r9,r4            /* load MSQ */
+        lvsl v18,r9,r4          /* set permute control vector */
+        addi r4, r4, 64
+        lvx v19,0,r4            /* load LSQ */
+        vperm v17,v0,v19,v18    /* align the data */
+
+        stvx v14,0,r6
+        stvx v15,r7,r6
+        stvx v16,r8,r6
+        stvx v17,r9,r6
+        addi r6, r6, 64
+
+	bdnz Lcopy_nalign_altivec
+	b Lcopy_remaining
+
+Lcopy_nalign_ldst:
+	ld  r0, 0(r4)
+	ld  r7, 8(r4)
+	ld  r8,16(r4)
+	ld  r9,24(r4)
+
+	std r0, 0(r6)
+	std r7, 8(r6)
+	std r8,16(r6)
+	std r9,24(r6)
+
+	ld  r0,32(r4)
+	ld  r7,40(r4)
+	ld  r8,48(r4)
+	ld  r9,56(r4)
+	addi r4,r4,64
+
+	std r0,32(r6)
+	std r7,40(r6)
+	std r8,48(r6)
+	std r9,56(r6)
+	addi r6,r6,64
+
+	bdnz Lcopy_nalign_ldst
+	b Lcopy_remaining
+
+END_GEN_TB (BP_SYM (memcpy), TB_TOCLESS)
+weak_alias (BP_SYM (memcpy), BP_SYM (largememcpy))
+libc_hidden_builtin_def (memcpy)
+libc_hidden_def (largememcpy)
diff -Naur libc-default/sysdeps/powerpc/powerpc64/power4/memcpy.S libc-e500mc-e5500-e6500-memcpy/sysdeps/powerpc/powerpc64/power4/memcpy.S
--- libc-default/sysdeps/powerpc/powerpc64/power4/memcpy.S	2013-03-20 03:58:23.219004831 -0500
+++ libc-e500mc-e5500-e6500-memcpy/sysdeps/powerpc/powerpc64/power4/memcpy.S	2013-05-27 06:04:57.769001387 -0500
@@ -414,5 +414,7 @@
     ld 31,-8(1)
     ld 3,-16(1)
     blr
-END_GEN_TB (BP_SYM (memcpy),TB_TOCLESS)
+END_GEN_TB (BP_SYM (memcpy), TB_TOCLESS)
 libc_hidden_builtin_def (memcpy)
+weak_alias (BP_SYM (memcpy), BP_SYM (largememcpy))
+libc_hidden_def (largememcpy)
diff -Naur libc-default/sysdeps/powerpc/powerpc64/power6/memcpy.S libc-e500mc-e5500-e6500-memcpy/sysdeps/powerpc/powerpc64/power6/memcpy.S
--- libc-default/sysdeps/powerpc/powerpc64/power6/memcpy.S	2013-03-20 03:58:23.232004831 -0500
+++ libc-e500mc-e5500-e6500-memcpy/sysdeps/powerpc/powerpc64/power6/memcpy.S	2013-05-27 06:05:13.894001375 -0500
@@ -1166,5 +1166,7 @@
     ld 31,-8(1)
     ld 3,-16(1)
     blr
-END_GEN_TB (BP_SYM (memcpy),TB_TOCLESS)
+END_GEN_TB (BP_SYM (memcpy), TB_TOCLESS)
 libc_hidden_builtin_def (memcpy)
+weak_alias (BP_SYM (memcpy), BP_SYM (largememcpy))
+libc_hidden_def (largememcpy)
diff -Naur libc-default/sysdeps/powerpc/powerpc64/power7/memcpy.S libc-e500mc-e5500-e6500-memcpy/sysdeps/powerpc/powerpc64/power7/memcpy.S
--- libc-default/sysdeps/powerpc/powerpc64/power7/memcpy.S	2013-03-20 03:58:23.223004831 -0500
+++ libc-e500mc-e5500-e6500-memcpy/sysdeps/powerpc/powerpc64/power7/memcpy.S	2013-05-27 06:05:28.487001380 -0500
@@ -503,5 +503,7 @@
 	ld	3,-16(1)
 	blr
 
-END_GEN_TB (BP_SYM (memcpy),TB_TOCLESS)
+END_GEN_TB (BP_SYM (memcpy), TB_TOCLESS)
 libc_hidden_builtin_def (memcpy)
+weak_alias (BP_SYM (memcpy), BP_SYM (largememcpy))
+libc_hidden_def (largememcpy)
diff -Naur libc-default/sysdeps/powerpc/Versions libc-e500mc-e5500-e6500-memcpy/sysdeps/powerpc/Versions
--- libc-default/sysdeps/powerpc/Versions	2013-03-20 03:58:23.271004832 -0500
+++ libc-e500mc-e5500-e6500-memcpy/sysdeps/powerpc/Versions	2013-05-27 04:25:31.666001378 -0500
@@ -9,6 +9,7 @@
   GLIBC_2.3.4 {
     _longjmp; __sigsetjmp; _setjmp;
     longjmp; setjmp;
+    largememcpy;
   }
   GLIBC_PRIVATE {
     __novmx__libc_longjmp; __novmx__libc_siglongjmp;
diff -Naur libc/sysdeps/powerpc/powerpc32/e6500/memcpy.S libc-e6500-memcpy/sysdeps/powerpc/powerpc32/e6500/memcpy.S
--- libc/sysdeps/powerpc/powerpc32/e6500/memcpy.S	2014-02-02 08:51:12.073968000 -0600
+++ libc-e6500-memcpy/sysdeps/powerpc/powerpc32/e6500/memcpy.S	2014-03-04 13:36:15.632096998 -0600
@@ -47,17 +47,13 @@
 	andi. r11,r0,15		/* count = r11 [temp & 3] */
 	beq L1
 
-	lwz r0, 0(r4)
-	lwz r7, 4(r4)
-	lwz r8, 8(r4)
-	lwz r9,12(r4)
+	ld r0, 0(r4)
+	ld r8, 8(r4)
 	subf r5,r11,r5		/* n = n - count */
 	add r4,r4,r11
 
-	stw r0, 0(r6)
-	stw r7, 4(r6)
-	stw r8, 8(r6)
-	stw r9,12(r6)
+	std r0, 0(r6)
+	std r8, 8(r6)
 	add r6,r6,r11
 
 L1:
@@ -95,50 +91,34 @@
 	mtcrf  0x01,r11
 	bf cr7*4+1,16f
 
-	lwz r0, 0(r4)		/* copy 32 bytes */
-	lwz r7, 4(r4)
-	lwz r8, 8(r4)
-	lwz r9,12(r4)
-
-	stw r0, 0(r6)
-	stw r7, 4(r6)
-	stw r8, 8(r6)
-	stw r9,12(r6)
-
-	lwz r0,16(r4)
-	lwz r7,20(r4)
-	lwz r8,24(r4)
-	lwz r9,28(r4)
+	ld r0, 0(r4)		/* copy 32 bytes */
+	ld r8, 8(r4)
+	std r0, 0(r6)
+	std r8, 8(r6)
+
+	ld r0,16(r4)
+	ld r8,24(r4)
+	std r0,16(r6)
+	std r8,24(r6)
+	
 	addi r4,r4,32
-
-	stw r0,16(r6)
-	stw r7,20(r6)
-	stw r8,24(r6)
-	stw r9,28(r6)
 	addi r6,r6,32
 
 16:
 	bf cr7*4+2,8f
 
-	lwz r0, 0(r4)		/* copy 16 bytes */
-	lwz r7, 4(r4)
-	lwz r8, 8(r4)
-	lwz r9,12(r4)
+	ld r0, 0(r4)		/* copy 16 bytes */
+	ld r8, 8(r4)
+	std r0, 0(r6)	
+	std r8, 8(r6)
+	
 	addi r4,r4,16
-
-	stw r0, 0(r6)	
-	stw r7, 4(r6)
-	stw r8, 8(r6)
-	stw r9,12(r6)
 	addi r6,r6,16
 8:
 	bf cr7*4+3, Lcopy_bytes
-	lwz r0, 0(r4)		/* copy 8 bytes */
-	lwz r7, 4(r4)
+	ld r0, 0(r4)		/* copy 8 bytes */
+	std r0, 0(r6)
 	addi r4,r4,8
-	
-	stw r0, 0(r6)
-	stw r7, 4(r6)
 	addi r6,r6,8
 
 Lcopy_bytes:
